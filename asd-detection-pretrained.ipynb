{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7624056,"sourceType":"datasetVersion","datasetId":4441306}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\n!pip install --upgrade tensorflow\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-04-12T09:17:02.382856Z","iopub.execute_input":"2024-04-12T09:17:02.383223Z","iopub.status.idle":"2024-04-12T09:18:22.458695Z","shell.execute_reply.started":"2024-04-12T09:17:02.383191Z","shell.execute_reply":"2024-04-12T09:18:22.457629Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-12 09:17:03.974759: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-12 09:17:03.974862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-12 09:17:04.094047: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nCollecting tensorflow\n  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nCollecting ml-dtypes~=0.3.1 (from tensorflow)\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.31.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nCollecting tensorboard<2.17,>=2.16 (from tensorflow)\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.1.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\nDownloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.2.0\n    Uninstalling ml-dtypes-0.2.0:\n      Successfully uninstalled ml-dtypes-0.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.16.1 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.1\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_images_from_directory(directory):\n    image_data = []\n    labels = []\n    classes = os.listdir(directory)\n    class_to_index = {class_name: i for i, class_name in enumerate(classes)}  # Assign numeric labels\n    for class_name in classes:\n        class_dir = os.path.join(directory, class_name)\n        for image_file in os.listdir(class_dir):\n            image_path = os.path.join(class_dir, image_file)\n            img = load_img(image_path, target_size=(224, 224))  # ResNet50 input size\n            img_array = img_to_array(img)\n            img_array = img_array / 255.0  # Normalize pixel values\n            image_data.append(img_array)\n            labels.append(class_to_index[class_name])  # Convert class name to numeric label\n    return np.array(image_data), np.array(labels)\n\ntrain_data, train_labels = load_images_from_directory('/kaggle/input/autism-dataset/dataset/train')\nvalidation_data, validation_labels = load_images_from_directory('/kaggle/input/autism-dataset/dataset/valid')","metadata":{"execution":{"iopub.status.busy":"2024-04-12T09:18:22.460726Z","iopub.execute_input":"2024-04-12T09:18:22.461650Z","iopub.status.idle":"2024-04-12T09:18:41.004497Z","shell.execute_reply.started":"2024-04-12T09:18:22.461619Z","shell.execute_reply":"2024-04-12T09:18:41.003493Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"base_model = ResNet50(weights='imagenet', include_top=False)\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# Add additional dense layers\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.25)(x)  # Add dropout for regularization\nx = Dense(128, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)  # Add dropout for regularization\n# Final Classification layer\npredictions = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T09:22:33.888170Z","iopub.execute_input":"2024-04-12T09:22:33.888965Z","iopub.status.idle":"2024-04-12T09:22:35.126068Z","shell.execute_reply.started":"2024-04-12T09:22:33.888932Z","shell.execute_reply":"2024-04-12T09:22:35.124966Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T09:22:40.184948Z","iopub.execute_input":"2024-04-12T09:22:40.185834Z","iopub.status.idle":"2024-04-12T09:22:40.195508Z","shell.execute_reply.started":"2024-04-12T09:22:40.185800Z","shell.execute_reply":"2024-04-12T09:22:40.194468Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.fit(train_data, train_labels, \n          epochs=20, \n          steps_per_epoch = 100, \n          validation_data=(validation_data, validation_labels))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T09:24:38.472422Z","iopub.execute_input":"2024-04-12T09:24:38.473303Z","iopub.status.idle":"2024-04-12T09:26:26.285390Z","shell.execute_reply.started":"2024-04-12T09:24:38.473268Z","shell.execute_reply":"2024-04-12T09:26:26.284395Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 130ms/step - accuracy: 0.7764 - loss: 0.4600 - val_accuracy: 0.5300 - val_loss: 2.4195\nEpoch 2/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7773 - loss: 0.4515 - val_accuracy: 0.5900 - val_loss: 1.2170\nEpoch 3/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7887 - loss: 0.4572 - val_accuracy: 0.5800 - val_loss: 1.3197\nEpoch 4/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7792 - loss: 0.4745 - val_accuracy: 0.6400 - val_loss: 0.7602\nEpoch 5/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7834 - loss: 0.4528 - val_accuracy: 0.6200 - val_loss: 1.2795\nEpoch 6/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7942 - loss: 0.4291 - val_accuracy: 0.5400 - val_loss: 1.5520\nEpoch 7/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7816 - loss: 0.4511 - val_accuracy: 0.7200 - val_loss: 0.9074\nEpoch 8/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7926 - loss: 0.4287 - val_accuracy: 0.6300 - val_loss: 1.4722\nEpoch 9/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7898 - loss: 0.4228 - val_accuracy: 0.6000 - val_loss: 0.6040\nEpoch 10/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8058 - loss: 0.4215 - val_accuracy: 0.5700 - val_loss: 1.5812\nEpoch 11/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8162 - loss: 0.4235 - val_accuracy: 0.5100 - val_loss: 1.8580\nEpoch 12/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7995 - loss: 0.4134 - val_accuracy: 0.5000 - val_loss: 5.3532\nEpoch 13/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8029 - loss: 0.4266 - val_accuracy: 0.5000 - val_loss: 4.5794\nEpoch 14/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8009 - loss: 0.4236 - val_accuracy: 0.5100 - val_loss: 3.2936\nEpoch 15/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8089 - loss: 0.3980 - val_accuracy: 0.5500 - val_loss: 1.6152\nEpoch 16/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8177 - loss: 0.4011 - val_accuracy: 0.6700 - val_loss: 0.6628\nEpoch 17/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8225 - loss: 0.3892 - val_accuracy: 0.5100 - val_loss: 4.1632\nEpoch 18/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8267 - loss: 0.3865 - val_accuracy: 0.6700 - val_loss: 1.1467\nEpoch 19/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8146 - loss: 0.4067 - val_accuracy: 0.5000 - val_loss: 7.9473\nEpoch 20/20\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8209 - loss: 0.3857 - val_accuracy: 0.5900 - val_loss: 1.1562\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d71086a3b20>"},"metadata":{}}]},{"cell_type":"code","source":"model.save('from_scratch.keras')","metadata":{"execution":{"iopub.status.busy":"2024-04-12T09:36:00.115890Z","iopub.execute_input":"2024-04-12T09:36:00.116614Z","iopub.status.idle":"2024-04-12T09:36:00.895246Z","shell.execute_reply.started":"2024-04-12T09:36:00.116581Z","shell.execute_reply":"2024-04-12T09:36:00.894384Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess test data\ntest_data = []\ntest_filenames = []\ntest_dir = '/kaggle/input/autism-dataset/dataset/test'\n\nfor image_file in os.listdir(test_dir):\n    image_path = os.path.join(test_dir, image_file)\n    img = load_img(image_path, target_size=(224, 224))  # ResNet50 input size\n    img_array = img_to_array(img)\n    img_array = img_array / 255.0  # Normalize pixel values\n    test_data.append(img_array)\n    test_filenames.append(image_file)\n\ntest_data = np.array(test_data)\n\n# Make predictions\npredictions = model.predict(test_data)\n\n# Since you don't have ground truth labels, you can save the predictions along with the filenames\n# For example, you can print the filename and corresponding predicted class probabilities\n# for filename, prediction in zip(test_filenames, predictions):\n#     print(f'Filename: {filename}, Predictions: {prediction}')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T09:36:04.795587Z","iopub.execute_input":"2024-04-12T09:36:04.796005Z","iopub.status.idle":"2024-04-12T09:36:13.907328Z","shell.execute_reply.started":"2024-04-12T09:36:04.795952Z","shell.execute_reply":"2024-04-12T09:36:13.906335Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1712914569.862712      91 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 447ms/step\n","output_type":"stream"}]}]}